{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"inference.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"_XmdU_fenKeD","colab_type":"code","outputId":"02760d8a-a93e-47ca-fc7d-577389f73a19","executionInfo":{"status":"ok","timestamp":1568892111856,"user_tz":-120,"elapsed":20426,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l-zU7FyE66e-","colab_type":"code","outputId":"1028cd75-de55-47a8-9f87-33e0178e1938","executionInfo":{"status":"ok","timestamp":1568892117620,"user_tz":-120,"elapsed":26184,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from torch import nn\n","from torch.nn import functional as F\n","import torch\n","import pickle\n","from keras.preprocessing import sequence\n","import string\n","import re"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"iLsfc0gg2Fp-","colab_type":"code","colab":{}},"source":["contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G0MgvZt8pYVh","colab_type":"code","colab":{}},"source":["def clean_special_chars(data):\n","    '''\n","    Credit goes to https://www.kaggle.com/gpreda/jigsaw-fast-compact-solution\n","    '''\n","    punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~`\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n","    def func(text, punct):\n","        for p in punct:\n","            text = text.replace(p, ' ')\n","        return text\n","\n","    return func(data, punct)\n","\n","\n","def clean_contractions(text, mapping):\n","    specials = [\"’\", \"‘\", \"´\", \"`\"]\n","    for s in specials:\n","        text = text.replace(s, \"'\")\n","\n","    for key in mapping.keys():\n","      if key in text:\n","        text = text.replace(key, mapping[key])\n","\n","    text = [word.replace(\"'s\", \"\") if word.endswith(\"'s\") else word for word in text.split()]\n","    text = ' '.join(text)\n","    return text\n","\n","\n","def replace_repeating_chars(text):\n","    for char in string.ascii_lowercase:\n","      pattern = char + '{2,}'\n","      text = re.sub(pattern, char, text)\n","    return text\n","\n","\n","def preprocess(data):\n","  data = data.lower()\n","  data = clean_contractions(data, contraction_mapping)\n","  data = clean_special_chars(data)\n","  #data = replace_repeating_chars(data)\n","  return data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yuwDHhZpokHj","colab_type":"code","colab":{}},"source":["class SpatialDropout(nn.Dropout2d):\n","    def forward(self, x):\n","        x = x.unsqueeze(2)   \n","        x = x.permute(0, 3, 2, 1)  \n","        x = super(SpatialDropout, self).forward(x)  \n","        x = x.permute(0, 3, 2, 1)  \n","        x = x.squeeze(2)  \n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w_yJPJQnQmsy","colab_type":"code","colab":{}},"source":["class IdentityLSTM(nn.Module):\n","  \n","    def __init__(self, max_features, n_targets=5, embed_size=300, units=16, num_layers=2):\n","      \n","        super(IdentityLSTM, self).__init__()\n","        \n","        self.embedding = nn.Embedding(max_features+1, embed_size)\n","        self.embedding_dropout = SpatialDropout(0.2)\n","        \n","        self.lstm = nn.LSTM(embed_size, units, bidirectional=True, dropout=0.2,\n","                            num_layers=num_layers, batch_first=True)\n","    \n","        self.linear = nn.Linear(units*4, units)     \n","        self.linear_out = nn.Linear(units, n_targets)\n","        \n","        \n","    def forward(self, x):\n","      \n","        m_embed = self.embedding(x)  \n","        m_embed = self.embedding_dropout(m_embed)\n","        \n","        m_lstm, _ = self.lstm(m_embed)\n","\n","        avg_pool = torch.mean(m_lstm, 1) # torch.Size([1, units*2])\n","        max_pool, _ = torch.max(m_lstm, 1) # torch.Size([1, units*2])\n","        m_conc = torch.cat((max_pool, avg_pool), 1) # torch.Size([1, units*4])\n","        m_conc_linear  = F.relu(self.linear(m_conc))    \n","        out = self.linear_out(m_conc_linear)   \n","        return out, 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EqGXEsFVQpgs","colab_type":"code","colab":{}},"source":["class ToxicLSTM(nn.Module):\n","  \n","    def __init__(self, max_features, n_targets=6, embed_size=300, units=64, num_layers=2):\n","      \n","        super(ToxicLSTM, self).__init__()\n","\n","        self.identity_lstm = IdentityLSTM(max_features)\n","        \n","        self.lstm = nn.LSTM(embed_size, units, bidirectional=True, dropout=0.2,\n","                            num_layers=num_layers, batch_first=True)\n","    \n","        self.linear = nn.Linear(units * 4, units * 2)\n","        self.linear_out = nn.Linear(units * 2 + 5, 1)\n","        self.linear_aux_out = nn.Linear(units * 2 + 5, n_targets)\n","        \n","        \n","    def forward(self, x):\n","\n","        identities, _ = self.identity_lstm(x)\n","      \n","        m_embed = self.identity_lstm.embedding(x)  \n","        m_embed = self.identity_lstm.embedding_dropout(m_embed)  \n","        m_lstm, _ = self.lstm(m_embed)\n","\n","        avg_pool = torch.mean(m_lstm, 1) # torch.Size([1, units*2])\n","        max_pool, _ = torch.max(m_lstm, 1) # torch.Size([1, units*2])\n","        m_conc = torch.cat(( max_pool, avg_pool), 1) # torch.Size([1, units*4+5])\n","   \n","        m_linear = torch.cat((identities, self.linear(m_conc)), 1)\n","        m_linear = torch.relu(m_linear)\n","        #hidden = m_conc + m_conc_linear\n","        \n","        result = self.linear_out(m_linear)\n","        aux_result = self.linear_aux_out(m_linear)\n","        out = torch.cat([result, aux_result], 1)      \n","\n","        return out, identities"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FKYhtG9EQrYO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IVAXlG2nncyi","colab_type":"code","colab":{}},"source":["tok_path = F\"/content/gdrive/My Drive/pytorch/tokenizer_best.pickle\"\n","with open(tok_path, 'rb') as f:\n","  tokenizer = pickle.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ldr7sCLwrSt1","colab_type":"code","outputId":"a29c937d-1e63-4c13-d7a6-572b2ec9921b","executionInfo":{"status":"ok","timestamp":1568892193647,"user_tz":-120,"elapsed":345,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["max_features = len(tokenizer.word_index) \n","print('max_features: {}'.format(max_features))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["max_features: 150000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XkiWUfhHQyQt","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UYrkIr9gnc1x","colab_type":"code","outputId":"2b60b1a9-e60a-4e83-90dd-9a2e9ec87929","executionInfo":{"status":"ok","timestamp":1568892264843,"user_tz":-120,"elapsed":4528,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}},"colab":{"base_uri":"https://localhost:8080/","height":276}},"source":["model_path = F\"/content/gdrive/My Drive/pytorch/model_lstm_toxicity.pt\"\n","state_dict = torch.load(model_path, map_location='cpu')\n","print('ROC-AUC score(s): {}'.format(state_dict['roc_auc']))\n","print('Validation Loss: {}'.format(state_dict['loss']))\n","model = ToxicLSTM(max_features)\n","model.load_state_dict(state_dict['state_dict'])\n","model.eval()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["ROC-AUC score(s): 0.9680310941580701\n","Validation Loss: 0.07392344654936121\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["ToxicLSTM(\n","  (identity_lstm): IdentityLSTM(\n","    (embedding): Embedding(150001, 300)\n","    (embedding_dropout): SpatialDropout(p=0.2)\n","    (lstm): LSTM(300, 16, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n","    (linear): Linear(in_features=64, out_features=16, bias=True)\n","    (linear_out): Linear(in_features=16, out_features=5, bias=True)\n","  )\n","  (lstm): LSTM(300, 64, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n","  (linear): Linear(in_features=256, out_features=128, bias=True)\n","  (linear_out): Linear(in_features=133, out_features=1, bias=True)\n","  (linear_aux_out): Linear(in_features=133, out_features=6, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"lDV6_0gJQx1H","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aaxb1hMd7PFw","colab_type":"code","colab":{}},"source":["categories_toxic = ['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat', 'sexual_explicit']\n","categories_identity = ['race', 'religion', 'sexuality', 'gender', 'disability']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZXyGpU_srp0E","colab_type":"code","colab":{}},"source":["def getPredictions(comments, model):\n","  comments = list(map(preprocess, comments))\n","  comments = tokenizer.texts_to_sequences(comments)\n","  MAX_LEN = max([len(x) for x in comments])\n","  comments = sequence.pad_sequences(comments, maxlen=MAX_LEN)\n","  comments = torch.tensor(comments, dtype=torch.long)\n","  toxicity, identities = model(comments)\n","  toxicity = torch.sigmoid(toxicity).tolist()\n","  identities = torch.sigmoid(identities).tolist()\n","  toxicity = [dict(zip(categories_toxic, x)) for x in toxicity]\n","  identities = [dict(zip(categories_identity, x)) for x in identities]\n","  return toxicity, identities\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"foKJVu0bs6ui","colab_type":"code","colab":{}},"source":["comments = ['I will kill you', 'Proud member of LGBT community', \n","            'fucking muslim', 'proud to be a muslim']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2wlSRtwfs64d","colab_type":"code","colab":{}},"source":["toxicity, identities = getPredictions(comments, model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eNkzVTEhmOD6","colab_type":"code","outputId":"909c97c5-f527-45be-a577-85447142e975","executionInfo":{"status":"ok","timestamp":1568892700148,"user_tz":-120,"elapsed":694,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}},"colab":{"base_uri":"https://localhost:8080/","height":245}},"source":["for comment, score in zip(comments, toxicity):\n","  print(comment)\n","  print(score)\n","  print()"],"execution_count":28,"outputs":[{"output_type":"stream","text":["I will kill you\n","{'target': 0.9714114665985107, 'severe_toxicity': 0.4973338842391968, 'obscene': 0.03671025112271309, 'identity_attack': 0.023082993924617767, 'insult': 0.10097718983888626, 'threat': 0.8975567817687988, 'sexual_explicit': 0.015554099343717098}\n","\n","Proud member of LGBT community\n","{'target': 0.0025926765520125628, 'severe_toxicity': 0.002852322533726692, 'obscene': 0.0018730449955910444, 'identity_attack': 0.06270429491996765, 'insult': 0.014784839004278183, 'threat': 0.001669012475758791, 'sexual_explicit': 0.002662821440026164}\n","\n","fucking muslim\n","{'target': 0.9998311996459961, 'severe_toxicity': 0.5174486637115479, 'obscene': 0.7958086133003235, 'identity_attack': 0.6911431550979614, 'insult': 0.750449001789093, 'threat': 0.01001792959868908, 'sexual_explicit': 0.05653193220496178}\n","\n","proud to be a muslim\n","{'target': 0.06221650913357735, 'severe_toxicity': 0.015402466058731079, 'obscene': 0.0021988593507558107, 'identity_attack': 0.25550368428230286, 'insult': 0.03137948736548424, 'threat': 0.0022361052688211203, 'sexual_explicit': 0.0005353098968043923}\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FRLrDKJLRh8a","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":245},"outputId":"e9e9536b-4baf-4092-99a3-44e8194e84b7","executionInfo":{"status":"ok","timestamp":1568892731502,"user_tz":-120,"elapsed":621,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}}},"source":["for comment, score in zip(comments, identities):\n","  print(comment)\n","  print(score)\n","  print()"],"execution_count":29,"outputs":[{"output_type":"stream","text":["I will kill you\n","{'race': 4.827248631045222e-05, 'religion': 0.00024556959397159517, 'sexuality': 3.2471340091433376e-05, 'gender': 0.0004187581653241068, 'disability': 7.396675937343389e-05}\n","\n","Proud member of LGBT community\n","{'race': 0.005679203663021326, 'religion': 0.03317807987332344, 'sexuality': 0.9704618453979492, 'gender': 0.004055017605423927, 'disability': 0.0003533287672325969}\n","\n","fucking muslim\n","{'race': 0.00185526127461344, 'religion': 0.9997912049293518, 'sexuality': 0.0372181236743927, 'gender': 0.0019051034469157457, 'disability': 0.0007742712623439729}\n","\n","proud to be a muslim\n","{'race': 0.0034487051889300346, 'religion': 0.999908447265625, 'sexuality': 0.3413546085357666, 'gender': 0.004958670120686293, 'disability': 0.0009836775716394186}\n","\n"],"name":"stdout"}]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"toxic_lstm_with_identities.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"C8qS00Q2eTfs","colab_type":"text"},"source":["**SETTING EVERYTHING UP (FOR GOOGLE COLAB)**"]},{"cell_type":"code","metadata":{"id":"eEzwASoWeRoS","colab_type":"code","outputId":"232289b3-6c3b-4332-e58b-43bd2d7c884c","executionInfo":{"status":"ok","timestamp":1568890682635,"user_tz":-120,"elapsed":20627,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RIuo6DxHdFeF","colab_type":"code","outputId":"76188ec9-2bda-4927-bffa-2185645aac75","executionInfo":{"status":"ok","timestamp":1568890812692,"user_tz":-120,"elapsed":132407,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}},"colab":{"base_uri":"https://localhost:8080/","height":190}},"source":["%%bash \n","curl -O https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n","wget https://nlp.stanford.edu/data/glove.840B.300d.zip"],"execution_count":2,"outputs":[{"output_type":"stream","text":["IOPub data rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_data_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"VRrmN_ureGmL","colab_type":"code","outputId":"21a408c7-5a4a-41aa-a6a5-ea533516cef2","executionInfo":{"status":"ok","timestamp":1568890909669,"user_tz":-120,"elapsed":227925,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}},"colab":{"base_uri":"https://localhost:8080/","height":86}},"source":["%%bash\n","unzip crawl-300d-2M.vec.zip \n","unzip glove.840B.300d.zip"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Archive:  crawl-300d-2M.vec.zip\n","  inflating: crawl-300d-2M.vec       \n","Archive:  glove.840B.300d.zip\n","  inflating: glove.840B.300d.txt     \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"En_yYsTMFXbd","colab_type":"code","colab":{}},"source":["%%bash\n","rm crawl-300d-2M.vec.zip\n","rm glove.840B.300d.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yZdpXoI8t1uG","colab_type":"code","outputId":"2b563831-b053-4e47-fe45-b21daef1a9a4","executionInfo":{"status":"ok","timestamp":1568890913254,"user_tz":-120,"elapsed":229787,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["!ls"],"execution_count":5,"outputs":[{"output_type":"stream","text":["crawl-300d-2M.vec  gdrive  glove.840B.300d.txt\tsample_data\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9nxMyuMMe3jv","colab_type":"text"},"source":["**Modelling**"]},{"cell_type":"code","metadata":{"id":"NnoX2sMxbipv","colab_type":"code","outputId":"474d2eb4-5f64-4ee9-81f6-ca8463813aac","executionInfo":{"status":"ok","timestamp":1568890920623,"user_tz":-120,"elapsed":7350,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import numpy as np\n","import pandas as pd\n","import os\n","import time\n","import gc\n","import random\n","import re\n","import string\n","from collections import Counter\n","from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n","from keras.preprocessing import text, sequence\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_auc_score\n","import torch\n","from torch import nn\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from torch.nn import functional as F\n","from torch.optim import Adam\n","from torch.optim.lr_scheduler import LambdaLR\n","import pickle\n","import os.path"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"plOlJMbguBgW","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eRjHtEEzepaJ","colab_type":"code","colab":{}},"source":["CRAWL_EMBEDDING_PATH = 'crawl-300d-2M.vec'\n","GLOVE_EMBEDDING_PATH = 'glove.840B.300d.txt'\n","NUM_WORDS = 150000"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hzmp9KERJCEO","colab_type":"code","colab":{}},"source":["path_data = F\"/content/gdrive/My Drive/pytorch/train_original.csv\" \n","train = pd.read_csv(path_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oOXNtXAXsBpu","colab_type":"code","colab":{}},"source":["contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ahw5s_vbHXLw","colab_type":"code","colab":{}},"source":["flatten = lambda l: [item for sublist in l for item in sublist]\n","\n","def clean_special_chars(data):\n","    '''\n","    Credit goes to https://www.kaggle.com/gpreda/jigsaw-fast-compact-solution\n","    '''\n","    punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~`\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n","    def func(text, punct):\n","        for p in punct:\n","            text = text.replace(p, ' ')\n","        return text\n","\n","    return func(data, punct)\n","\n","\n","def clean_contractions(text, mapping):\n","    specials = [\"’\", \"‘\", \"´\", \"`\"]\n","    for s in specials:\n","        text = text.replace(s, \"'\")\n","\n","    for key in mapping.keys():\n","      if key in text:\n","        text = text.replace(key, mapping[key])\n","\n","    text = [word.replace(\"'s\", \"\") if word.endswith(\"'s\") else word for word in text.split()]\n","    text = ' '.join(text)\n","    return text\n","\n","\n","def replace_repeating_chars(text):\n","    for char in string.ascii_lowercase:\n","      pattern = char + '{2,}'\n","      text = re.sub(pattern, char, text)\n","    return text\n","\n","\n","def preprocess(data):\n","  data = data.lower()\n","  data = clean_contractions(data, contraction_mapping)\n","  data = clean_special_chars(data)\n","  #data = replace_repeating_chars(data)\n","  return data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a-7AYBwcJEL-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MPMPPLiC1fY-","colab_type":"code","colab":{}},"source":["analysis = False\n","if analysis:\n","  comments = train['comment_text'].apply(lambda x: preprocess(x))\n","  pretokenizer = text.Tokenizer()\n","  pretokenizer.fit_on_texts(list(comments))\n","  reverse_word_map = dict(map(reversed, pretokenizer.word_index.items()))\n","  pre_tokenized = pretokenizer.texts_to_sequences(comments)\n","  pre_tokenized = flatten(pre_tokenized)\n","  print('Total number of words: {}'.format(len(pre_tokenized)))\n","  print('Total number of unique words: {}'.format(len(set(pre_tokenized))))\n","  not_alpha = [word for word in pre_tokenized if (not reverse_word_map[word].isalpha() and not reverse_word_map[word].isdigit())]\n","  print('Total number of non-alpha words: {}'.format(len(not_alpha)))\n","  print('Total number of unique non-alpha words: {}'.format(len(set(not_alpha))))\n","  not_alpha = [reverse_word_map[word] for word in not_alpha]\n","  counter_not_alpha = Counter(not_alpha)\n","  counter_alpha = Counter([reverse_word_map[word] for word in pre_tokenized if reverse_word_map[word].isalpha()])\n","  inv_counter_alpha = counter_alpha.most_common()\n","  inv_counter_alpha.reverse()\n","  counter = Counter([reverse_word_map[word] for word in pre_tokenized])\n","  once = sum([1 for k,v in counter_alpha.most_common() if v == 1])\n","  twice = sum([1 for k,v in counter_alpha.most_common() if v == 2])\n","  print('Number of once words: {}'.format(once))\n","  print('Number of twice words: {}'.format(twice))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zNu-EfdBIlEp","colab_type":"code","colab":{}},"source":["def bucketing(data_x, data_y, n_buckets=32):\n","  data_x = [(data_x[i], i) for i in range(len(data_x))]\n","  data_x.sort(key = lambda x: len(x[0]))\n","  data_x = list(filter(lambda x: len(x[0]) != 0, data_x))\n","  data_x = np.array_split(data_x, n_buckets)\n","  for bucket in data_x:\n","    np.random.shuffle(bucket)\n","  np.random.shuffle(data_x)\n","  data_x = flatten(data_x)\n","  data_x = [x.tolist() for x in data_x]\n","  data_x, permutation = zip(*data_x)\n","  data_y = data_y.iloc[np.array(permutation)]\n","  data_y = data_y.reset_index(drop=True)\n","  return data_x, data_y\n","\n","def slicing_index(x):\n","    non_zero_mask = x != 0\n","    mask_max_values, mask_max_indices = torch.max(non_zero_mask, dim=1)\n","    return int(min(mask_max_indices))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6weM3sR2IeuV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8FOni6Vbeqff","colab_type":"code","colab":{}},"source":["def get_coefs(word, *arr):\n","    return word, np.asarray(arr, dtype='float32')\n","\n","def load_embeddings(path):\n","    with open(path) as f:\n","        return dict(get_coefs(*line.strip().split(' ')) for line in f)\n","\n","def build_matrix(word_index, path):\n","    embedding_index = load_embeddings(path)\n","    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n","    unknown_words = []\n","    \n","    for word, i in word_index.items():\n","        try:\n","            embedding_matrix[i] = embedding_index[word]\n","        except KeyError:\n","            unknown_words.append(word)\n","    return embedding_matrix, unknown_words"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0hlQKkO8refM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2nJi6yhSRkmM","colab_type":"code","colab":{}},"source":["train['target'] = np.where(train['target'] >= 0.5, 1, 0)\n","train['comment_text'] = train['comment_text'].apply(lambda x: preprocess(x))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tIs1xRXCenbd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M7nbx1oHbGIm","colab_type":"code","colab":{}},"source":["RACE, RELIGION, SEXUALITY, GENDER, DISABILITY = 'race', 'religion', 'sexuality', 'gender', 'disability'\n","\n","categories_tox = ['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat', 'sexual_explicit']\n","\n","categories_iden = {'asian': RACE, 'black': RACE, 'latino': RACE, 'white': RACE, 'other_race_or_ethnicity': RACE,         \n","                   'atheist': RELIGION, 'buddhist': RELIGION, 'christian': RELIGION, 'hindu': RELIGION, \n","                   'jewish': RELIGION, 'muslim': RELIGION, 'other_religion': RELIGION,\n","                   'bisexual': SEXUALITY, 'heterosexual': SEXUALITY, 'homosexual_gay_or_lesbian': SEXUALITY,\n","                   'other_sexual_orientation': SEXUALITY,\n","                   'female': GENDER, 'male': GENDER, 'other_gender': GENDER, 'transgender': GENDER, \n","                   'intellectual_or_learning_disability': DISABILITY, 'physical_disability': DISABILITY,\n","                   'psychiatric_or_mental_illness': DISABILITY, 'other_disability': DISABILITY}\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4F__15EykA5x","colab_type":"code","colab":{}},"source":["y_train_toxicity = train[categories_tox]\n","x_train_toxicity = train['comment_text']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NQIMQJfPk4pZ","colab_type":"code","outputId":"95c9a346-cfd5-481f-919b-f940c6a916a8","executionInfo":{"status":"ok","timestamp":1568891048594,"user_tz":-120,"elapsed":135256,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["train_iden = train[train['identity_annotator_count'] > 0]\n","print('Number of entries with identity count: {}'.format(len(train_iden)))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Number of entries with identity count: 405130\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zzc-hpuckEvw","colab_type":"code","outputId":"e6edeb98-de33-47ff-c475-43db58bf8011","executionInfo":{"status":"ok","timestamp":1568891050057,"user_tz":-120,"elapsed":136696,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}},"colab":{"base_uri":"https://localhost:8080/","height":245}},"source":["identities = [RACE, RELIGION, SEXUALITY, GENDER, DISABILITY]\n","for identity in identities:\n","  train_iden[identity] = train_iden[[k for k,v in categories_iden.items() if v == identity]].max(axis = 1)\n","  train_iden[identity] = np.where(train_iden[identity] >= 0.5, 1, 0)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  This is separate from the ipykernel package so we can avoid doing imports until\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  after removing the cwd from sys.path.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"RMpI5NDkkEyn","colab_type":"code","colab":{}},"source":["y_train_identity = train_iden[identities]\n","x_train_identity  = train_iden['comment_text']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SEcSEdddkE1l","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U4WoS-j5rMv-","colab_type":"code","outputId":"d264c395-f765-4e66-ca16-a7175057796a","executionInfo":{"status":"ok","timestamp":1568891050790,"user_tz":-120,"elapsed":137406,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["#https://github.com/keras-team/keras/issues/8092\n","\n","path_tok = F\"/content/gdrive/My Drive/pytorch/tokenizer_best.pickle\" \n","\n","if os.path.isfile(path_tok):\n","  print(\"Unpickling\")\n","  with open(path_tok, 'rb') as f:\n","    tokenizer = pickle.load(f)\n","else:\n","  tokenizer = text.Tokenizer(oov_token='_UNK_', num_words=NUM_WORDS)\n","  tokenizer.fit_on_texts(list(x_train_toxicity))\n","  tokenizer.word_index = {e:i for e,i in tokenizer.word_index.items() if i <= NUM_WORDS}\n","  with open(path_tok, 'wb') as f:\n","    pickle.dump(tokenizer, f)\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Unpickling\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iEVzInlfpF_d","colab_type":"code","outputId":"b53a12af-3b2c-4793-c79b-bd3a12f8237d","executionInfo":{"status":"ok","timestamp":1568891050791,"user_tz":-120,"elapsed":137395,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["max_features = None or len(tokenizer.word_index)\n","print('max_features: {}'.format(max_features))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["max_features: 150000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JZn-sCs3pGzy","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vkk67uQMo7Kd","colab_type":"code","colab":{}},"source":["def get_dataloaders(x_train, y_train, tokenizer, max_len=250, batch_size=512, test_size=0.2):\n","  x_train = tokenizer.texts_to_sequences(x_train)\n","  x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n","  train_x, validation_x, train_y, validation_y = train_test_split(x_train, y_train, random_state=29, test_size=test_size)\n","\n","  train_x = torch.tensor(train_x, dtype=torch.long).cuda()\n","  validation_x = torch.tensor(validation_x, dtype=torch.long).cuda()\n","  train_y = torch.tensor(np.array(train_y), dtype=torch.float32).cuda()\n","  validation_y = torch.tensor(np.array(validation_y), dtype=torch.float32).cuda() \n","\n","  train_data = TensorDataset(train_x, train_y)\n","  train_sampler = RandomSampler(train_data)\n","  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","  validation_data = TensorDataset(validation_x, validation_y)\n","  validation_sampler = SequentialSampler(validation_data)\n","  validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n","\n","  print(\"Len of training data / Num of batches: {} / {}\".format(len(train_data), len(train_dataloader)))\n","  print(\"Len of validation data / Num of batches: {} / {}\".format(len(validation_data), len(validation_dataloader)))\n","  print()\n","\n","  return train_dataloader, validation_dataloader"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wsDBi6M8o7NB","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6IQXPwbaqVdB","colab_type":"code","outputId":"714900f1-ce65-45fd-de04-ea8e1e6a3c4e","executionInfo":{"status":"ok","timestamp":1568891180411,"user_tz":-120,"elapsed":266993,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["train_dataloader_tox, validation_dataloader_tox = get_dataloaders(x_train_toxicity, y_train_toxicity, tokenizer)\n","train_dataloader_iden, validation_dataloader_iden = get_dataloaders(x_train_identity, y_train_identity, tokenizer)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Len of training data / Num of batches: 1443899 / 2821\n","Len of validation data / Num of batches: 360975 / 706\n","\n","Len of training data / Num of batches: 324104 / 634\n","Len of validation data / Num of batches: 81026 / 159\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PGHYjiWI0VH_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6_mQrUhU0VOG","colab_type":"code","outputId":"137e5f21-3ad8-4623-9f5d-4ddf36fa9943","executionInfo":{"status":"ok","timestamp":1568891493354,"user_tz":-120,"elapsed":579922,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["crawl_matrix, unknown_words_crawl = build_matrix(tokenizer.word_index, CRAWL_EMBEDDING_PATH)\n","print('unknown words (crawl): ', len(unknown_words_crawl))\n","\n","glove_matrix, unknown_words_glove = build_matrix(tokenizer.word_index, GLOVE_EMBEDDING_PATH)\n","print('unknown words (glove): ', len(unknown_words_glove))\n","\n","embed_matrix = np.true_divide(np.add(crawl_matrix, glove_matrix), 2)\n","print(embed_matrix.shape)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["unknown words (crawl):  41655\n","unknown words (glove):  39320\n","(150001, 300)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sAc66Zrsz9DB","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tCHAZZC8Tj-e","colab_type":"code","colab":{}},"source":["def get_roc_auc(labels, preds, auc=True):\n","\n","  if auc:\n","    labels = np.array(labels)\n","    size = len(labels.shape)\n","    if size == 2:\n","      roc_auc_macro = roc_auc_score(labels, preds, average='macro')\n","      roc_auc_weighted = roc_auc_score(labels, preds, average='weighted')\n","      print(\"ROC-AUC macro: {}\".format(roc_auc_macro))\n","      print(\"ROC-AUC weighted: {}\".format(roc_auc_weighted)) \n","      roc_auc = (roc_auc_macro, roc_auc_weighted) \n","    else:\n","      roc_auc = roc_auc_score(labels, preds)\n","      print(\"ROC-AUC: {}\".format(roc_auc))\n","  else:\n","    roc_auc = 'NA'\n","\n","  return roc_auc\n","\n","def slice_batch(batch):\n","  i = slicing_index(batch)\n","  return batch[:, i:]\n","\n","\n","def train(model, train_dataloader, validation_dataloader, path_model, lr=0.01, \n","          epochs=10, slicing=True, auc=True, auc_on_all=True):\n","\n","  optimizer = Adam(model.parameters(), lr=lr)\n","  scheduler = LambdaLR(optimizer, lambda epoch: 0.6 ** epoch)\n","  criterion = torch.nn.BCEWithLogitsLoss()\n","  sigmoid = nn.Sigmoid()\n","  \n","  best_loss = 100\n","\n","  for i in range(epochs):\n","      \n","    print('Epoch: {}'.format(i+1))\n","    \n","    # training\n","    epoch_train_loss = 0\n","    scheduler.step()\n","    model.train()\n","  \n","    for batch_x, batch_y in tqdm(train_dataloader):\n","                \n","      if slicing: batch_x = slice_batch(batch_x)\n","      \n","      optimizer.zero_grad()   \n","      logits, _ = model(batch_x)\n","      loss = criterion(logits, batch_y)     \n","      epoch_train_loss += loss.item()   \n","      loss.backward()\n","      optimizer.step()\n","      \n","    print(\"Train loss: {}\".format(epoch_train_loss/len(train_dataloader)))\n","  \n","    # evaluation\n","    model.eval()\n","    epoch_test_loss, preds_full, labels_full = 0, [], []\n","    \n","    for batch_x, batch_y in validation_dataloader:\n","\n","      if slicing: batch_x = slice_batch(batch_x)\n","\n","      with torch.no_grad():\n","        logits, _  = model(batch_x)\n","\n","      loss = criterion(logits, batch_y)\n","      epoch_test_loss += loss.item()\n","\n","      preds = sigmoid(logits)\n","\n","      if not auc_on_all: \n","        preds = preds[:, 0]\n","        batch_y = batch_y[:, 0]\n","\n","      preds = preds.detach().cpu().numpy()\n","      batch_y = batch_y.to('cpu').numpy()\n","\n","      preds_full += preds.tolist()\n","      labels_full += batch_y.tolist()\n","\n","\n","    roc_auc = get_roc_auc(labels_full, preds_full, auc=auc)\n","        \n","    current_loss = epoch_test_loss/len(validation_dataloader)\n","    print(\"Validation loss: {}\".format(current_loss))    \n","          \n","    if current_loss < best_loss:\n","      best_loss = current_loss       \n","      state = {'state_dict': model.state_dict(),\n","              'loss': current_loss,\n","              'roc_auc': roc_auc}\n","      torch.save(state, path_model)\n","      print('Saving model')\n","      print()\n","\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a-JbP9Y402r0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ajLyXJyII5Rt","colab_type":"code","colab":{}},"source":["class SpatialDropout(nn.Dropout2d):\n","    def forward(self, x):\n","        x = x.unsqueeze(2)   \n","        x = x.permute(0, 3, 2, 1)  \n","        x = super(SpatialDropout, self).forward(x)  \n","        x = x.permute(0, 3, 2, 1)  \n","        x = x.squeeze(2)  \n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oz0aBK1an8M0","colab_type":"code","colab":{}},"source":["class IdentityLSTM(nn.Module):\n","  \n","    def __init__(self, max_features, n_targets=5, embed_size=300, units=16, num_layers=2):\n","      \n","        super(IdentityLSTM, self).__init__()\n","        \n","        self.embedding = nn.Embedding(max_features+1, embed_size)\n","        self.embedding_dropout = SpatialDropout(0.2)\n","        \n","        self.lstm = nn.LSTM(embed_size, units, bidirectional=True, dropout=0.2,\n","                            num_layers=num_layers, batch_first=True)\n","    \n","        self.linear = nn.Linear(units*4, units)     \n","        self.linear_out = nn.Linear(units, n_targets)\n","        \n","        \n","    def forward(self, x):\n","      \n","        m_embed = self.embedding(x)  \n","        m_embed = self.embedding_dropout(m_embed)\n","        \n","        m_lstm, _ = self.lstm(m_embed)\n","\n","        avg_pool = torch.mean(m_lstm, 1) # torch.Size([1, units*2])\n","        max_pool, _ = torch.max(m_lstm, 1) # torch.Size([1, units*2])\n","        m_conc = torch.cat((max_pool, avg_pool), 1) # torch.Size([1, units*4])\n","        m_conc_linear  = F.relu(self.linear(m_conc))    \n","        out = self.linear_out(m_conc_linear)   \n","        return out, 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"awRtWIvAmZTY","colab":{}},"source":["class ToxicLSTM(nn.Module):\n","  \n","    def __init__(self, max_features, n_targets=6, embed_size=300, units=64, num_layers=2):\n","      \n","        super(ToxicLSTM, self).__init__()\n","\n","        self.identity_lstm = IdentityLSTM(max_features)\n","        \n","        self.lstm = nn.LSTM(embed_size, units, bidirectional=True, dropout=0.2,\n","                            num_layers=num_layers, batch_first=True)\n","    \n","        self.linear = nn.Linear(units * 4, units * 2)\n","        self.linear_out = nn.Linear(units * 2 + 5, 1)\n","        self.linear_aux_out = nn.Linear(units * 2 + 5, n_targets)\n","        \n","        \n","    def forward(self, x):\n","\n","        identities, _ = self.identity_lstm(x)\n","      \n","        m_embed = self.identity_lstm.embedding(x)  \n","        m_embed = self.identity_lstm.embedding_dropout(m_embed)  \n","        m_lstm, _ = self.lstm(m_embed)\n","\n","        avg_pool = torch.mean(m_lstm, 1) # torch.Size([1, units*2])\n","        max_pool, _ = torch.max(m_lstm, 1) # torch.Size([1, units*2])\n","        m_conc = torch.cat(( max_pool, avg_pool), 1) # torch.Size([1, units*4+5])\n","   \n","        m_linear = torch.cat((identities, self.linear(m_conc)), 1)\n","        m_linear = torch.relu(m_linear)\n","        #hidden = m_conc + m_conc_linear\n","        \n","        result = self.linear_out(m_linear)\n","        aux_result = self.linear_aux_out(m_linear)\n","        out = torch.cat([result, aux_result], 1)      \n","\n","        return out, identities"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"74rLHkdLflWH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d3pXO586hvcn","colab_type":"text"},"source":["**MODEL FOR IDENTITY ATTRIBUTION**"]},{"cell_type":"code","metadata":{"id":"VCpm2mwuUKYH","colab_type":"code","colab":{}},"source":["path_model_iden = F\"/content/gdrive/My Drive/pytorch/model_lstm_identity.pt\" \n","model_identity = IdentityLSTM(max_features)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AszIvv-1ZKTt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"b6defcce-b65a-45e0-e792-549c82c02d70","executionInfo":{"status":"ok","timestamp":1568891796778,"user_tz":-120,"elapsed":831,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}}},"source":["pretrained_identity = True\n","\n","if pretrained_identity:\n","  state_dict = torch.load(path_model_iden)\n","  print('ROC-AUC score(s): {}'.format(state_dict['roc_auc']))\n","  print('Validation Loss: {}'.format(state_dict['loss']))\n","  model_identity.load_state_dict(state_dict['state_dict'])\n","  model_identity.cuda()\n","  model_identity.eval()"],"execution_count":55,"outputs":[{"output_type":"stream","text":["ROC-AUC score(s): (0.9966615977371251, 0.9961783216946134)\n","Validation Loss: 0.03529140219654677\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-kPsiqQZPyTO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":138},"outputId":"38123ad0-428b-4b53-a203-eb2ed2845ed3","executionInfo":{"status":"ok","timestamp":1568891943099,"user_tz":-120,"elapsed":2996,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}}},"source":["model_identity"],"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["IdentityLSTM(\n","  (embedding): Embedding(150001, 300)\n","  (embedding_dropout): SpatialDropout(p=0.2)\n","  (lstm): LSTM(300, 16, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n","  (linear): Linear(in_features=64, out_features=16, bias=True)\n","  (linear_out): Linear(in_features=16, out_features=5, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"code","metadata":{"id":"HypL8_xiZjAx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"190d9933-2fcc-40f4-d568-e2438b98f736","executionInfo":{"status":"ok","timestamp":1568891978149,"user_tz":-120,"elapsed":550,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}}},"source":["model_test = True\n","if model_test:\n","  model_identity.eval()\n","  sigmoid = nn.Sigmoid()\n","  x,y = next(iter(train_dataloader_iden))\n","  x = slice_batch(x)\n","  print('Batch dim after slicing: {}'. format(x.size()))\n","  out, _ = model_identity(x) \n","  out = sigmoid(out)\n","  print('Output dim: {}'. format(out.size()))"],"execution_count":61,"outputs":[{"output_type":"stream","text":["Batch dim after slicing: torch.Size([512, 186])\n","Output dim: torch.Size([512, 5])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m6wpmnQtPwwi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NUgDLu97fcIo","colab_type":"code","colab":{}},"source":["if not pretrained_identity:\n","  model_identity.embedding.weight = nn.Parameter(torch.tensor(embed_matrix, dtype=torch.float32))\n","  model_identity.embedding.weight.requires_grad = False\n","  model_identity.cuda()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yjxMzIvbVakX","colab_type":"code","colab":{}},"source":["if not pretrained_identity:\n","  gc.collect()\n","  model_identity = train(model_identity, train_dataloader_iden, validation_dataloader_iden, path_model_iden, \n","                         lr=0.01, epochs=10, slicing=True, auc=True, auc_on_all=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l9dBadtYOtfF","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ie7jpi35h65Q","colab_type":"text"},"source":["**MODEL FOR TOXICITY SCORES**"]},{"cell_type":"code","metadata":{"id":"VBHiy7ucaKlj","colab_type":"code","colab":{}},"source":["path_model_tox = F\"/content/gdrive/My Drive/pytorch/model_lstm_toxicity.pt\" \n","model_toxicity = ToxicLSTM(max_features)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"03bLv2rDe2FJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"9ddc6f1e-9c32-4929-a05e-9554364456bb","executionInfo":{"status":"ok","timestamp":1568891988895,"user_tz":-120,"elapsed":864,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}}},"source":["pretrained_toxicity = True\n","\n","if pretrained_toxicity:\n","  state_dict = torch.load(path_model_tox)\n","  print('ROC-AUC score(s): {}'.format(state_dict['roc_auc']))\n","  print('Validation Loss: {}'.format(state_dict['loss']))\n","  model_toxicity.load_state_dict(state_dict['state_dict'])\n","  model_toxicity.cuda()\n","  model_toxicity.eval()"],"execution_count":65,"outputs":[{"output_type":"stream","text":["ROC-AUC score(s): 0.9680310941580701\n","Validation Loss: 0.07392344654936121\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T1JXgsnwL1Nj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"d8b69bcb-b420-4e9b-996c-90822dd1c1a4","executionInfo":{"status":"ok","timestamp":1568892024814,"user_tz":-120,"elapsed":1043,"user":{"displayName":"Tatiana Gaponova","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDpCaJky1NViCoPTZF8Ew290A8YpEMACebsz-aP6QY=s64","userId":"17758316458603777674"}}},"source":["model_test = True\n","if model_test:\n","  model_toxicity.eval()\n","  sigmoid = nn.Sigmoid()\n","  x,y = next(iter(train_dataloader_tox))\n","  x = slice_batch(x)\n","  print('Batch dim after slicing: {}'. format(x.size()))\n","  toxicity, identities = model_toxicity(x) \n","  toxicity = sigmoid(toxicity)\n","  identities = sigmoid(identities)\n","  print('Toxicity output dim: {}'. format(toxicity.size()))\n","  print('Identities output dim: {}'. format(identities.size()))"],"execution_count":67,"outputs":[{"output_type":"stream","text":["Batch dim after slicing: torch.Size([512, 186])\n","Toxicity output dim: torch.Size([512, 7])\n","Identities output dim: torch.Size([512, 5])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bPZlfrz-Lwet","colab_type":"code","colab":{}},"source":["if not pretrained_toxicity:\n","  model_toxicity.identity_lstm = model_identity\n","  for param in model_toxicity.identity_lstm.parameters():\n","    param.requires_grad = False \n","  model_toxicity.cuda()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Q0kJqQ2gtup","colab_type":"code","colab":{}},"source":["if not pretrained_toxicity:\n","  gc.collect()\n","  train(model_toxicity, train_dataloader_tox, validation_dataloader_tox, path_model_tox, \n","        lr=0.01, epochs=10, slicing=True, auc=True, auc_on_all=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i36J4iMhgtsc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eJ-1_U1EqvL_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ZzoP-MUqvOr","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_uB-7NJzGjCd","colab_type":"text"},"source":["**Credits**\n","\n","Extremely grateful to the authors of the following kernels:\n","\n","1.   https://www.kaggle.com/bminixhofer/simple-lstm-pytorch-version/\n","2.   https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing\n","\n"]}]}